{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elcdxfFld_-A"
      },
      "source": [
        "## In-Context Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oD70dEOd_-A"
      },
      "source": [
        "With the increasing size and complexity of model architectures, [large language models (LLMs) have demonstrated in-context learning (ICL) ability](https://splab.sdu.edu.cn/GPT3.pdf). This enables LLMs to perform tasks and generate responses based on the context provided in the input prompt, without requiring explicit fine-tuning or retraining. In practice, this context includes one or a few demonstration examples that guide (condition) the model in performing downstream tasks such as classification, question/answering, information extraction, reasoning, and data analysis. [In 2022, researchers at Anthropic investigated the hypothesis that *'induction [attention] heads'* were the primary mechanism driving ICL](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). These specialized units attend earlier parts of the input to copy and complete sequences, which would allow models to adapt to patterns and generate responses aligned to the provided context.\n",
        "\n",
        "This notebook explores the concept of ICL, demonstrating its practical application in Named Entity Recognition (NER). NER is a `Natural Language Processing` task that identifies and classifies named entities (NE) into predefined semantic categories (such as persons, organizations, locations, events, time expressions, and quantities). By converting raw text into structured information, NER makes data more actionable, facilitating tasks like information extraction, data aggregation, analytics, and social media monitoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNi3jOkrd_-B"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/dcarpintero/generative-ai-101/blob/main/static/in_context_learning.png?raw=1\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYal1XOad_-B"
      },
      "source": [
        "### 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKzKBLqVd_-B"
      },
      "source": [
        "#### 1.1 Install/Upgrade Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ganA9C1Rd_-B"
      },
      "outputs": [],
      "source": [
        "%pip install openai tenacity --quiet | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GhlaZOcd_-B"
      },
      "source": [
        "#### 1.2 Load packages and OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7696RZ4fd_-C"
      },
      "source": [
        "You can generate an API key in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyvi7e0vd_-C"
      },
      "source": [
        "This notebook works with the latest OpeanAI models `gpt-4o` and `gpt-4o-mini`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v7XGsqccd_-C"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import openai\n",
        "\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=' %(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "OPENAI_MODEL = 'deepseek-chat'\n",
        "#client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"sk-10756b0e11834102825b28fd79ba6680\", base_url=\"https://api.deepseek.com\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PhAf7Rcd_-C"
      },
      "source": [
        "### 2. Define the NER labels to be Identified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVOijLqid_-C"
      },
      "source": [
        "We define a standard set of NER labels to showcase a wide range of use cases. However, for our specific task of enriching text with knowledge base links, only a subset is practically required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vGIYt_4Id_-C"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"person\",      # people, including fictional characters\n",
        "    \"fac\",         # buildings, airports, highways, bridges\n",
        "    \"org\",         # organizations, companies, agencies, institutions\n",
        "    \"gpe\",         # geopolitical entities like countries, cities, states\n",
        "    \"loc\",         # non-gpe locations\n",
        "    \"product\",     # vehicles, foods, appareal, appliances, software, toys\n",
        "    \"event\",       # named sports, scientific milestones, historical events\n",
        "    \"work_of_art\", # titles of books, songs, movies\n",
        "    \"law\",         # named laws, acts, or legislations\n",
        "    \"language\",    # any named language\n",
        "    \"date\",        # absolute or relative dates or periods\n",
        "    \"time\",        # time units smaller than a day\n",
        "    \"percent\",     # percentage (e.g., \"twenty percent\", \"18%\")\n",
        "    \"money\",       # monetary values, including unit\n",
        "    \"quantity\",    # measurements, e.g., weight or distance\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmJvqqcid_-C"
      },
      "source": [
        "### 3. Prepare messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfuw2nPzd_-C"
      },
      "source": [
        "The [chat completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api) takes a list of messages as input and delivers a model-generated message as an output. While the chat format is primarily designed for facilitating multi-turn conversations, it is equally efficient for single-turn tasks without any preceding conversation. For our purposes, we will specify a message for the system, assistant, and user roles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlQSIM8Gd_-C"
      },
      "source": [
        "#### 3.1 System Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XhVOm7yd_-C"
      },
      "source": [
        "The `system message` (prompt) sets the assistant's behavior by defining its desired persona and task. We also delineate the specific set of entity labels we aim to identify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dmse5rd_-C"
      },
      "source": [
        "Although one can instruct the model to format its response, it has to be noted that both `gpt-4o` and `gpt-4o-mini` have been fine-tuned to discern when a function should be invoked, and to reply with `JSON` formatted according to the function's signature. This capability streamlines our prompt and enables us to receive structured data directly from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A0xlSAJJd_-C"
      },
      "outputs": [],
      "source": [
        "def system_message(labels):\n",
        "    return f\"\"\"\n",
        "You are an expert in Natural Language Processing. Your task is to identify common Named Entities (NER) in a given text.\n",
        "The possible common Named Entities (NER) types are exclusively: ({\", \".join(labels)}).\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeKzdB15d_-C"
      },
      "source": [
        "#### 3.2 Assistant Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swgSuoXFd_-D"
      },
      "source": [
        "`Assistant messages` usually store previous assistant responses. However, as in our scenario, they can also be crafted to provide examples of the desired behavior. While OpenAI is able to execute `zero-shot` Named Entity Recognition, we have found that a `one-shot` approach produces more precise results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GpaT4HBdd_-D"
      },
      "outputs": [],
      "source": [
        "def assisstant_message():\n",
        "    return f\"\"\"\n",
        "EXAMPLE:\n",
        "    Text: 'In Germany, in 1440, goldsmith Johannes Gutenberg invented the movable-type printing press. His work led to an information revolution and the unprecedented mass-spread /\n",
        "    of literature throughout Europe. Modelled on the design of the existing screw presses, a single Renaissance movable-type printing press could produce up to 3,600 pages per workday.'\n",
        "    {{\n",
        "        \"gpe\": [\"Germany\", \"Europe\"],\n",
        "        \"date\": [\"1440\"],\n",
        "        \"person\": [\"Johannes Gutenberg\"],\n",
        "        \"product\": [\"movable-type printing press\"],\n",
        "        \"event\": [\"Renaissance\"],\n",
        "        \"quantity\": [\"3,600 pages\"],\n",
        "        \"time\": [\"workday\"]\n",
        "    }}\n",
        "--\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_V0pJExd_-D"
      },
      "source": [
        "#### 3.3 User Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIurUhSBd_-D"
      },
      "source": [
        "The `user message` provides the specific text for the assistant task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ot_9-MHhd_-D"
      },
      "outputs": [],
      "source": [
        "def user_message(text):\n",
        "    return f\"\"\"\n",
        "TASK:\n",
        "    Text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0IPSpId_-D"
      },
      "source": [
        "### 4. Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu-ullkzd_-D"
      },
      "source": [
        "#### 4.1 Chat Completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQKwGRUqd_-D"
      },
      "source": [
        "The Chat Completions API accepts inputs via the messages parameter, which is an array of message objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JeP0phXod_-D"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(3))\n",
        "def run_openai_task(labels, text):\n",
        "    messages = [\n",
        "          {\"role\": \"system\", \"content\": system_message(labels=labels)},\n",
        "          {\"role\": \"assistant\", \"content\": assisstant_message()},\n",
        "          {\"role\": \"user\", \"content\": user_message(text=text)}\n",
        "      ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"deepseek-chat\",\n",
        "    messages=messages,\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "\n",
        "    return {\"response\": response,\n",
        "            \"response_message\": response_message.content}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__DmNJ8Td_-D"
      },
      "source": [
        "#### 4.2 Run OpenAI Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "467gXQdhd_-D"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"The Beatles were an English rock band formed in Liverpool in 1960, comprising John Lennon, Paul McCartney, George Harrison, and Ringo Starr.\n",
        "          Rooted in skiffle, beat and 1950s rock 'n' roll, their sound incorporated elements of classical music and traditional pop in innovative ways.\n",
        "          The Beatles are the best-selling music act of all time, with estimated sales of 600 million units worldwide.\n",
        "       \"\"\"\n",
        "result = run_openai_task(labels, text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_82h00G_d_-D",
        "outputId": "5bba2e06-0571-4c9a-8ec5-a00fbf618fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: {\n",
            "    \"org\": [\"The Beatles\"],\n",
            "    \"gpe\": [\"Liverpool\"],\n",
            "    \"date\": [\"1960\"],\n",
            "    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"],\n",
            "    \"event\": [\"skiffle\", \"beat\", \"1950s rock 'n' roll\"],\n",
            "    \"quantity\": [\"600 million units\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "logging.info(f\"Response: {result['response_message']}\")\n",
        "print(f\"Response: {result['response_message']}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}